<div align="center">

<img src="https://llmonitor.com/logo.png" style='border-radius: 12px;' width="50"/>

# LLMonitor

**Monitoring for AI apps and agent**

[website](https://llmonitor.com) - [docs](https://llmonitor.com/docs) - [demo](https://app.llmonitor.com/demo) - [![npm version](https://badge.fury.io/js/llmonitor.svg)](https://badge.fury.io/js/llmonitor)

---

</div>

Features:

- Simple to self host (deploy to Vercel & Supabase)
- Use with any model, not just OpenAI
- Log agent runs and identify errors with full history
- Records completion requests, search and explore request history in the dashboard
- Latency and token analytics

Currently, a [JS client](https://github.com/llmonitor/llmonitor-js) is available with Python in the works.

- Doesn't add latency with an extra endpoint
- Langchain support

## Todo

- [ ] Demo dashboard
- [ ] Demo dashboard
- [ ] Search on agent and LLM pages
- [ ] Date filtering on agent and LLM pages
- [x] Users Tracking
- [ ] Embeddings analytics
- [ ] Tools views

## License

This project is licensed under the Apache 2.0 License.
