<div align="center">

# ðŸ¤– LLMonitor

**Monitoring for <span style="background-color: rgb(219, 234, 254);">AI apps and agent</span>**

[website](https://llmonitor.com) - [docs](https://llmonitor.com/docs) - [demo](https://app.llmonitor.com/demo) - [![npm version](https://badge.fury.io/js/llmonitor.svg)](https://badge.fury.io/js/llmonitor)

---  

</div>

Features:
* Simple to self host (deploy to Vercel & Supabase)
* Use with any model, not just OpenAI
* Log agent runs and identify errors with full history
* Records completion requests, search and explore request history in the dashboard
* Latency and token analytics

Currently, a [JS client](https://github.com/llmonitor/llmonitor-js) is available with Python in the works.
* Doesn't add latency with an extra endpoint
* Langchain support

## Todo 

- [x] Analytics dashboard
- [ ] Demo dashboard
- [ ] Agent debugger
- [ ] Add search on agent and LLM pages
- [ ] Update `setup-dump.sql` to latest
- [ ] Users support
- [ ] Embedding models analytics
- [ ] Tools views 
- [ ] Agents alert
- [x] Sidebar layout 
- [x] Agent view
- [x] Generations view