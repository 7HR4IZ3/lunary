<div align="center">

# 📈 llmonitor

**Open-source monitoring & observability for AI apps and agents**

[website](https://llmonitor.com) - [docs](https://llmonitor.com/docs) - [demo](https://app.llmonitor.com/demo)

[![npm version](https://badge.fury.io/js/llmonitor.svg)](https://badge.fury.io/js/llmonitor) - ![Discord](https://img.shields.io/badge/Discord-Join%20Chat-violet?labelColor=purple&style=flat&logo=discord&logoColor=white)

</div>

- 🧑‍💻 Simple to self-host (deploy to Vercel & Supabase)
- 💵 Cost, token & latency analytics
- 👪 Track users
- 🐛 Debug agents with traces
- 🔍 Inspect full requests
- 🤖 Use with any model, not just OpenAI
- 📦 Integrate in 2 minutes

<video controls width="900"><source src="https://llmonitor.com/videos/demo-annotated.mp4"></video>

## ⚙️ Integration

Modules available for:

- [JavaScript](https://github.com/llmonitor/llmonitor-js)
- Python (coming soon)

LLMonitor natively supports:

- LangChain (JS & Python)
- OpenAI module
- LiteLLM

Additionally you can use it with any framework by wrapping the relevant methods.

## 📚 Documentation

Full documentation is available [on the website](https://llmonitor.com/docs/intro).

## 🙋 Support

Chat with us on [Discord](https://discord.gg/8PafSG58kK) or email one of the founders at vince@llmonitor.com.

## License

This project is licensed under the Apache 2.0 License.
